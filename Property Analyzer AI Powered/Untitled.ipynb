{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e96db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting earthengine-api\n",
      "  Downloading earthengine_api-1.5.15-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.1)\n",
      "Collecting google-cloud-storage (from earthengine-api)\n",
      "  Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting google-api-python-client>=1.12.1 (from earthengine-api)\n",
      "  Downloading google_api_python_client-2.169.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=1.4.1 (from earthengine-api)\n",
      "  Downloading google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-auth-httplib2>=0.0.3 (from earthengine-api)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httplib2<1dev,>=0.9.2 (from earthengine-api)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from earthengine-api) (2.31.0)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 (from google-api-python-client>=1.12.1->earthengine-api)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.12.1->earthengine-api)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api) (5.5.2)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.4.1->earthengine-api)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.4.1->earthengine-api)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting google-cloud-core<3.0dev,>=2.4.2 (from google-cloud-storage->earthengine-api)\n",
      "  Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage->earthengine-api)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage->earthengine-api)\n",
      "  Downloading google_crc32c-1.7.1-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->earthengine-api) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->earthengine-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->earthengine-api) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->earthengine-api) (2022.12.7)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in c:\\users\\adity\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (6.30.2)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading earthengine_api-1.5.15-py3-none-any.whl (462 kB)\n",
      "   ---------------------------------------- 0.0/462.6 kB ? eta -:--:--\n",
      "   --------------------------------------  460.8/462.6 kB 30.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 462.6/462.6 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.4/125.4 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "Downloading google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/13.3 MB 4.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.3/13.3 MB 13.8 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.9/13.3 MB 13.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.4/13.3 MB 13.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.1/13.3 MB 14.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.7/13.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/13.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/13.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/13.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/13.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/13.3 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/13.3 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.6/13.3 MB 7.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/13.3 MB 7.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.8/13.3 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.4/13.3 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.6/13.3 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.8/13.3 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.0/13.3 MB 8.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.3/13.3 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.5/13.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.7/13.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.9/13.3 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.1/13.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.3/13.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.5/13.3 MB 7.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.7/13.3 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.8/13.3 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.0/13.3 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.1/13.3 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.1/13.3 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.1/13.3 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.2/13.3 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.3/13.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.5/13.3 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.7/13.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.0/13.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.2/13.3 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.5/13.3 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.8/13.3 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.2/13.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.5/13.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.7/13.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.0/13.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.5/13.3 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.7/13.3 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.0/13.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.2/13.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.3/13.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 216.1/216.1 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl (174 kB)\n",
      "   ---------------------------------------- 0.0/174.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 174.9/174.9 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 160.1/160.1 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.7.1-cp311-cp311-win_amd64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.3/81.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 181.3/181.3 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 122.9/294.5 kB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 286.7/294.5 kB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 294.5/294.5 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.1 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 61.4/83.1 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 83.1/83.1 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, pyasn1, proto-plus, httplib2, googleapis-common-protos, google-crc32c, geographiclib, rsa, pyasn1-modules, google-resumable-media, geopy, google-auth, google-auth-httplib2, google-api-core, google-cloud-core, google-api-python-client, google-cloud-storage, earthengine-api\n",
      "Successfully installed earthengine-api-1.5.15 geographiclib-2.0 geopy-2.4.1 google-api-core-2.24.2 google-api-python-client-2.169.0 google-auth-2.40.1 google-auth-httplib2-0.2.0 google-cloud-core-2.4.3 google-cloud-storage-3.1.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 httplib2-0.22.0 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install earthengine-api geopy numpy pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adeef898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--address ADDRESS] [--lat LAT] [--lon LON] [--value VALUE] [--size SIZE]\n",
      "                             [--bedrooms BEDROOMS] [--output OUTPUT] [--interactive]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\adity\\AppData\\Roaming\\jupyter\\runtime\\kernel-1da1d8eb-5992-479f-b28c-9a8d1978c08d.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Property Analyzer: AI-Powered Real Estate Assessment Tool\n",
    "\n",
    "This is a modified version that works without requiring Google Earth Engine\n",
    "authentication. It uses simulated data for demonstration purposes.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "import requests\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "from geopy.geocoders import Nominatim, GoogleV3, ArcGIS\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class PropertyAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the PropertyAnalyzer with required components.\"\"\"\n",
    "        try:\n",
    "            # Initialize geocoder\n",
    "            self.geolocator = Nominatim(user_agent=\"property_analyzer\")\n",
    "            \n",
    "            # Initialize ML model for property valuation\n",
    "            self.value_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            \n",
    "            print(\"Property Analyzer initialized successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Initialization error: {e}\")\n",
    "    \n",
    "    def geocode_address(self, address):\n",
    "        \"\"\"Convert address to coordinates.\"\"\"\n",
    "        try:\n",
    "            location = self.geolocator.geocode(address)\n",
    "            if location:\n",
    "                return {\n",
    "                    'lat': location.latitude,\n",
    "                    'lon': location.longitude,\n",
    "                    'address': location.address\n",
    "                }\n",
    "            else:\n",
    "                # For demo purposes, generate random coordinates if geocoding fails\n",
    "                print(f\"Could not geocode address: {address}, using simulated location data\")\n",
    "                return {\n",
    "                    'lat': random.uniform(30, 45),\n",
    "                    'lon': random.uniform(-120, -70),\n",
    "                    'address': address\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Geocoding error: {e}\")\n",
    "            # For demo purposes, generate random coordinates\n",
    "            print(\"Using simulated location data\")\n",
    "            return {\n",
    "                'lat': random.uniform(30, 45),\n",
    "                'lon': random.uniform(-120, -70),\n",
    "                'address': address\n",
    "            }\n",
    "\n",
    "    def get_property_coordinates(self, address=None, lat=None, lon=None):\n",
    "        \"\"\"Get coordinates either from address or direct lat/lon input.\"\"\"\n",
    "        if address:\n",
    "            return self.geocode_address(address)\n",
    "        elif lat is not None and lon is not None:\n",
    "            return {'lat': lat, 'lon': lon, 'address': f\"Coordinates: {lat}, {lon}\"}\n",
    "        else:\n",
    "            raise ValueError(\"Either address or lat/lon coordinates must be provided\")\n",
    "\n",
    "    def analyze_flood_risk(self, location_data, radius_meters=1000):\n",
    "        \"\"\"Simulate flood risk based on location data.\"\"\"\n",
    "        try:\n",
    "            # Get coordinates\n",
    "            lat = location_data['lat']\n",
    "            lon = location_data['lon']\n",
    "            \n",
    "            # For demo purposes, generate simulated data\n",
    "            # Use latitude to influence the flood risk (more northern = less risk in this simulation)\n",
    "            lat_factor = (lat - 30) / 15  # Normalize latitude between 30-45 to 0-1\n",
    "            lat_factor = max(0, min(1, lat_factor))  # Clamp between 0-1\n",
    "            \n",
    "            # Use longitude as a random seed for some variability\n",
    "            random.seed(int((lon + 180) * 100))\n",
    "            \n",
    "            # Simulated elevation (higher = lower flood risk)\n",
    "            mean_elevation = 50 + random.uniform(-20, 100) + lat_factor * 50\n",
    "            \n",
    "            # Simulated distance to water (higher = lower flood risk)\n",
    "            min_distance = 100 + random.uniform(0, 900) - lat_factor * 200\n",
    "            \n",
    "            # Simulated water presence\n",
    "            water_presence = max(0, min(100, 30 - lat_factor * 20 + random.uniform(-10, 10)))\n",
    "            \n",
    "            # Calculate risk score\n",
    "            # Low elevation + close to water = higher risk\n",
    "            elev_factor = max(0, min(1, mean_elevation / 100))  # 0-100m scale\n",
    "            dist_factor = max(0, min(1, min_distance / radius_meters))\n",
    "            \n",
    "            # Combined risk (0-100 scale, higher is riskier)\n",
    "            risk_score = int(100 * (1 - (elev_factor * 0.7 + dist_factor * 0.3)))\n",
    "            \n",
    "            # Risk level categories\n",
    "            if risk_score < 20:\n",
    "                risk_level = \"Very Low\"\n",
    "            elif risk_score < 40:\n",
    "                risk_level = \"Low\"\n",
    "            elif risk_score < 60:\n",
    "                risk_level = \"Moderate\"\n",
    "            elif risk_score < 80:\n",
    "                risk_level = \"High\"\n",
    "            else:\n",
    "                risk_level = \"Very High\"\n",
    "            \n",
    "            return {\n",
    "                \"elevation_m\": mean_elevation,\n",
    "                \"distance_to_water_m\": min_distance,\n",
    "                \"flood_risk_score\": risk_score,\n",
    "                \"flood_risk_level\": risk_level,\n",
    "                \"water_presence_pct\": water_presence\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Flood risk analysis error: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def analyze_sun_exposure(self, location_data):\n",
    "        \"\"\"Simulate sun exposure throughout the year.\"\"\"\n",
    "        try:\n",
    "            # Get coordinates\n",
    "            lat = location_data['lat']\n",
    "            lon = location_data['lon']\n",
    "            \n",
    "            # Use latitude to influence sun exposure (higher latitudes get less sun)\n",
    "            lat_factor = 1 - abs(lat - 35) / 15  # Best sun around latitude 35, decreasing as you move away\n",
    "            lat_factor = max(0.5, min(1, lat_factor))  # Clamp between 0.5-1\n",
    "            \n",
    "            # Use longitude as a random seed for some variability\n",
    "            random.seed(int((lon + 180) * 100) + 1)  # Different seed than flood risk\n",
    "            \n",
    "            # Sun angles for different times of year\n",
    "            sun_angles = [\n",
    "                {\"season\": \"Winter\", \"time\": \"Morning\", \"azimuth\": 120, \"elevation\": 20},\n",
    "                {\"season\": \"Winter\", \"time\": \"Noon\", \"azimuth\": 180, \"elevation\": 30},\n",
    "                {\"season\": \"Winter\", \"time\": \"Afternoon\", \"azimuth\": 240, \"elevation\": 20},\n",
    "                {\"season\": \"Spring/Fall\", \"time\": \"Morning\", \"azimuth\": 90, \"elevation\": 30},\n",
    "                {\"season\": \"Spring/Fall\", \"time\": \"Noon\", \"azimuth\": 180, \"elevation\": 60},\n",
    "                {\"season\": \"Spring/Fall\", \"time\": \"Afternoon\", \"azimuth\": 270, \"elevation\": 30},\n",
    "                {\"season\": \"Summer\", \"time\": \"Morning\", \"azimuth\": 60, \"elevation\": 40},\n",
    "                {\"season\": \"Summer\", \"time\": \"Noon\", \"azimuth\": 180, \"elevation\": 80},\n",
    "                {\"season\": \"Summer\", \"time\": \"Afternoon\", \"azimuth\": 300, \"elevation\": 40}\n",
    "            ]\n",
    "            \n",
    "            results = []\n",
    "            base_score = int(70 * lat_factor + random.uniform(-5, 15))\n",
    "            \n",
    "            for angle in sun_angles:\n",
    "                # Simulate hillshade values\n",
    "                season_factor = 1.0\n",
    "                if angle[\"season\"] == \"Winter\":\n",
    "                    season_factor = 0.7\n",
    "                elif angle[\"season\"] == \"Summer\":\n",
    "                    season_factor = 1.2\n",
    "                \n",
    "                time_factor = 1.0\n",
    "                if angle[\"time\"] == \"Morning\":\n",
    "                    time_factor = 0.9\n",
    "                elif angle[\"time\"] == \"Afternoon\":\n",
    "                    time_factor = 0.95\n",
    "                \n",
    "                sun_score = int(base_score * season_factor * time_factor)\n",
    "                sun_score = max(0, min(100, sun_score + random.uniform(-10, 10)))\n",
    "                \n",
    "                results.append({\n",
    "                    \"season\": angle[\"season\"],\n",
    "                    \"time_of_day\": angle[\"time\"],\n",
    "                    \"sun_exposure_score\": sun_score\n",
    "                })\n",
    "            \n",
    "            # Calculate average sun exposure\n",
    "            valid_scores = [r[\"sun_exposure_score\"] for r in results if r[\"sun_exposure_score\"] is not None]\n",
    "            avg_score = sum(valid_scores) / len(valid_scores) if valid_scores else None\n",
    "            \n",
    "            # Determine overall rating\n",
    "            if avg_score is not None:\n",
    "                if avg_score >= 80:\n",
    "                    rating = \"Excellent\"\n",
    "                elif avg_score >= 60:\n",
    "                    rating = \"Good\"\n",
    "                elif avg_score >= 40:\n",
    "                    rating = \"Moderate\"\n",
    "                else:\n",
    "                    rating = \"Poor\"\n",
    "            else:\n",
    "                rating = \"Unknown\"\n",
    "            \n",
    "            return {\n",
    "                \"detailed_sun_exposure\": results,\n",
    "                \"average_sun_score\": avg_score,\n",
    "                \"sun_exposure_rating\": rating\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Sun exposure analysis error: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def analyze_neighborhood_development(self, location_data, years_back=10, radius_km=2):\n",
    "        \"\"\"Simulate development trends in the neighborhood.\"\"\"\n",
    "        try:\n",
    "            # Get coordinates\n",
    "            lat = location_data['lat']\n",
    "            lon = location_data['lon']\n",
    "            \n",
    "            # For demo purposes, generate simulated data\n",
    "            # Use longitude to influence development (more eastern areas develop faster in this simulation)\n",
    "            lon_factor = (lon + 120) / 50  # Normalize longitude\n",
    "            lon_factor = max(0, min(1, lon_factor))  # Clamp between 0-1\n",
    "            \n",
    "            # Use latitude as a random seed for some variability\n",
    "            random.seed(int(lat * 100) + 2)  # Different seed than previous analyses\n",
    "            \n",
    "            # Set up time periods to analyze\n",
    "            current_year = datetime.now().year\n",
    "            start_year = current_year - years_back\n",
    "            \n",
    "            # Generate development trend data\n",
    "            development_trend = []\n",
    "            \n",
    "            # Base growth rate (% per year), influenced by location\n",
    "            base_growth = 1.5 + lon_factor * 2 + random.uniform(-0.5, 1.5)\n",
    "            \n",
    "            # Starting development percentage\n",
    "            start_pct = 25 + random.uniform(-10, 40)\n",
    "            \n",
    "            # Generate data for available years\n",
    "            available_years = [y for y in range(start_year, current_year + 1, 2)]\n",
    "            \n",
    "            for i, year in enumerate(available_years):\n",
    "                # Calculate built-up percentage with some random variation\n",
    "                year_factor = i / (len(available_years) - 1) if len(available_years) > 1 else 0.5\n",
    "                pct = start_pct * (1 + base_growth/100) ** (i * 2)  # Compound growth\n",
    "                pct = pct + random.uniform(-2, 2)  # Add small random variations\n",
    "                pct = max(0, min(100, pct))  # Clamp between 0-100\n",
    "                \n",
    "                development_trend.append({\n",
    "                    \"year\": year,\n",
    "                    \"built_up_percentage\": pct\n",
    "                })\n",
    "            \n",
    "            # Calculate development growth rate\n",
    "            if len(development_trend) >= 2:\n",
    "                first = development_trend[0][\"built_up_percentage\"]\n",
    "                last = development_trend[-1][\"built_up_percentage\"]\n",
    "                years_diff = development_trend[-1][\"year\"] - development_trend[0][\"year\"]\n",
    "                \n",
    "                if years_diff > 0 and first is not None and last is not None and first > 0:\n",
    "                    annual_growth_rate = ((last / first) ** (1 / years_diff) - 1) * 100\n",
    "                else:\n",
    "                    annual_growth_rate = base_growth\n",
    "            else:\n",
    "                annual_growth_rate = base_growth\n",
    "            \n",
    "            # Determine growth category\n",
    "            if annual_growth_rate > 5:\n",
    "                growth_category = \"Rapid Growth\"\n",
    "            elif annual_growth_rate > 2:\n",
    "                growth_category = \"Moderate Growth\"\n",
    "            elif annual_growth_rate > 0.5:\n",
    "                growth_category = \"Stable Growth\"\n",
    "            elif annual_growth_rate > -0.5:\n",
    "                growth_category = \"Stable\"\n",
    "            else:\n",
    "                growth_category = \"Declining\"\n",
    "            \n",
    "            return {\n",
    "                \"development_trend\": development_trend,\n",
    "                \"analysis_period\": f\"{start_year}-{current_year}\",\n",
    "                \"annual_growth_rate_pct\": annual_growth_rate,\n",
    "                \"development_category\": growth_category\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Neighborhood development analysis error: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def analyze_traffic_noise(self, location_data, radius_meters=500):\n",
    "        \"\"\"Simulate traffic and noise levels.\"\"\"\n",
    "        try:\n",
    "            # Get coordinates\n",
    "            lat = location_data['lat']\n",
    "            lon = location_data['lon']\n",
    "            \n",
    "            # For demo purposes, generate simulated data\n",
    "            # Use location to affect noise levels (lower latitudes = higher noise in this simulation)\n",
    "            # This simulates the idea that more southern areas might be more urban/populated\n",
    "            lat_factor = 1 - (lat - 30) / 15  # Normalize latitude between 30-45 to 1-0\n",
    "            lat_factor = max(0, min(1, lat_factor))  # Clamp between 0-1\n",
    "            \n",
    "            # Use longitude as a random seed\n",
    "            random.seed(int((lon + 180) * 100) + 3)  # Different seed than previous analyses\n",
    "            \n",
    "            # Simulated distances to different road types\n",
    "            # Lower latitude = more likely to be close to highways\n",
    "            highway_factor = lat_factor * 0.7 + random.random() * 0.3\n",
    "            highway_distance = None if random.random() > highway_factor else int(200 + random.uniform(0, 1500) * (1 - highway_factor))\n",
    "            \n",
    "            major_road_factor = lat_factor * 0.5 + 0.3\n",
    "            major_road_distance = int(100 + random.uniform(0, 500) * (1 - major_road_factor))\n",
    "            \n",
    "            minor_road_distance = int(10 + random.uniform(0, 200))\n",
    "            \n",
    "            # Simulated road density based on latitude (higher in more populated areas)\n",
    "            road_density = max(0.1, min(5, lat_factor * 3 + random.uniform(-0.5, 1.5)))\n",
    "            \n",
    "            # Calculate noise score\n",
    "            # Highway factor (0-100, higher means more noise)\n",
    "            if highway_distance is None or highway_distance > 1000:\n",
    "                highway_factor = 0\n",
    "            else:\n",
    "                highway_factor = max(0, 100 - (highway_distance / 10))\n",
    "            \n",
    "            # Major road factor\n",
    "            if major_road_distance > 500:\n",
    "                major_road_factor = 0\n",
    "            else:\n",
    "                major_road_factor = max(0, 100 - (major_road_distance / 5))\n",
    "            \n",
    "            # Minor road factor\n",
    "            if minor_road_distance > 200:\n",
    "                minor_road_factor = 0\n",
    "            else:\n",
    "                minor_road_factor = max(0, 100 - (minor_road_distance / 2))\n",
    "            \n",
    "            # Density factor\n",
    "            density_factor = min(100, road_density * 20)\n",
    "            \n",
    "            # Combined noise score (0-100)\n",
    "            noise_score = int(0.4 * highway_factor + 0.3 * major_road_factor +\n",
    "                              0.2 * minor_road_factor + 0.1 * density_factor)\n",
    "            \n",
    "            # Determine noise level\n",
    "            if noise_score < 20:\n",
    "                noise_level = \"Very Low\"\n",
    "            elif noise_score < 40:\n",
    "                noise_level = \"Low\"\n",
    "            elif noise_score < 60:\n",
    "                noise_level = \"Moderate\"\n",
    "            elif noise_score < 80:\n",
    "                noise_level = \"High\"\n",
    "            else:\n",
    "                noise_level = \"Very High\"\n",
    "            \n",
    "            return {\n",
    "                \"distance_to_highway_m\": highway_distance,\n",
    "                \"distance_to_major_road_m\": major_road_distance,\n",
    "                \"distance_to_minor_road_m\": minor_road_distance,\n",
    "                \"road_density_km_per_km2\": road_density,\n",
    "                \"estimated_noise_score\": noise_score,\n",
    "                \"estimated_noise_level\": noise_level\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Traffic and noise analysis error: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def predict_property_value(self, location_data, current_value=None, property_size=None, bedrooms=None):\n",
    "        \"\"\"\n",
    "        Predict future property value based on location data, current market trends,\n",
    "        and historical development patterns.\n",
    "        \n",
    "        Note: This is a simplified prediction model for demonstration purposes.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Gather all our analyzed data\n",
    "            flood_risk = self.analyze_flood_risk(location_data)\n",
    "            sun_exposure = self.analyze_sun_exposure(location_data)\n",
    "            development = self.analyze_neighborhood_development(location_data)\n",
    "            traffic = self.analyze_traffic_noise(location_data)\n",
    "            \n",
    "            # Create features for our model\n",
    "            features = {\n",
    "                'lat': location_data['lat'],\n",
    "                'lon': location_data['lon'],\n",
    "                'flood_risk_score': flood_risk.get('flood_risk_score', 50),\n",
    "                'avg_sun_score': sun_exposure.get('average_sun_score', 50),\n",
    "                'development_rate': development.get('annual_growth_rate_pct', 1),\n",
    "                'noise_score': traffic.get('estimated_noise_score', 50)\n",
    "            }\n",
    "            \n",
    "            if property_size is not None:\n",
    "                features['property_size'] = property_size\n",
    "            \n",
    "            if bedrooms is not None:\n",
    "                features['bedrooms'] = bedrooms\n",
    "            \n",
    "            # For demonstration, we'll use a simplified formula instead of an actual trained model\n",
    "            \n",
    "            if current_value is None:\n",
    "                # If no current value provided, we can't make a percentage prediction\n",
    "                return {\n",
    "                    \"message\": \"Current property value required for prediction\",\n",
    "                    \"recommendation\": \"For value prediction, please provide the current property value\"\n",
    "                }\n",
    "            \n",
    "            # Factors that positively affect value:\n",
    "            # - Higher development rate\n",
    "            # - Higher sun exposure\n",
    "            # - Lower flood risk\n",
    "            # - Lower noise\n",
    "            \n",
    "            # Calculate a simple growth factor\n",
    "            development_factor = min(5, max(0, features['development_rate']))\n",
    "            \n",
    "            quality_factor = (\n",
    "                (100 - features['flood_risk_score']) / 100 * 0.3 +  # Lower flood risk is better\n",
    "                features['avg_sun_score'] / 100 * 0.3 +             # Higher sun exposure is better\n",
    "                (100 - features['noise_score']) / 100 * 0.4         # Lower noise is better\n",
    "            )\n",
    "            \n",
    "            # Base annual appreciation\n",
    "            base_appreciation = 2.0  # 2% base annual appreciation\n",
    "            \n",
    "            # Adjusted appreciation rate\n",
    "            adjusted_rate = base_appreciation + (development_factor * 0.5) + (quality_factor * 2 - 1)\n",
    "            adjusted_rate = max(0, min(10, adjusted_rate))  # Cap between 0-10%\n",
    "            \n",
    "            # 5-year prediction\n",
    "            five_year_value = current_value * ((1 + (adjusted_rate / 100)) ** 5)\n",
    "            \n",
    "            # Value prediction outcomes\n",
    "            value_prediction = {\n",
    "                \"current_value\": current_value,\n",
    "                \"estimated_annual_appreciation_pct\": round(adjusted_rate, 2),\n",
    "                \"five_year_projected_value\": int(five_year_value),\n",
    "                \"projected_gain_pct\": round(((five_year_value / current_value) - 1) * 100, 2)\n",
    "            }\n",
    "            \n",
    "            # Add investment rating\n",
    "            if adjusted_rate > 6:\n",
    "                value_prediction[\"investment_potential\"] = \"Excellent\"\n",
    "            elif adjusted_rate > 4:\n",
    "                value_prediction[\"investment_potential\"] = \"Good\"\n",
    "            elif adjusted_rate > 2:\n",
    "                value_prediction[\"investment_potential\"] = \"Average\"\n",
    "            else:\n",
    "                value_prediction[\"investment_potential\"] = \"Below Average\"\n",
    "                \n",
    "            return value_prediction\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Property value prediction error: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def generate_comprehensive_report(self, address=None, lat=None, lon=None,\n",
    "                                     current_value=None, property_size=None, bedrooms=None):\n",
    "        \"\"\"Generate a comprehensive property analysis report.\"\"\"\n",
    "        try:\n",
    "            # Get location data\n",
    "            location_data = self.get_property_coordinates(address, lat, lon)\n",
    "            if not location_data:\n",
    "                return {\"error\": \"Could not geocode the provided address or coordinates\"}\n",
    "            \n",
    "            print(f\"Analyzing property at: {location_data['address']}\")\n",
    "            \n",
    "            # Run all analyses\n",
    "            flood_risk = self.analyze_flood_risk(location_data)\n",
    "            sun_exposure = self.analyze_sun_exposure(location_data)\n",
    "            development = self.analyze_neighborhood_development(location_data)\n",
    "            traffic = self.analyze_traffic_noise(location_data)\n",
    "            \n",
    "            value_prediction = None\n",
    "            if current_value is not None:\n",
    "                value_prediction = self.predict_property_value(\n",
    "                    location_data, current_value, property_size, bedrooms\n",
    "                )\n",
    "            \n",
    "            # Generate overall property score (0-100)\n",
    "            scores = []\n",
    "            \n",
    "            # Flood risk (lower is better)\n",
    "            if 'flood_risk_score' in flood_risk and flood_risk['flood_risk_score'] is not None:\n",
    "                flood_score = 100 - flood_risk['flood_risk_score']\n",
    "                scores.append(('Flood Safety', flood_score))\n",
    "            \n",
    "            # Sun exposure (higher is better)\n",
    "            if 'average_sun_score' in sun_exposure and sun_exposure['average_sun_score'] is not None:\n",
    "                scores.append(('Sun Exposure', sun_exposure['average_sun_score']))\n",
    "            \n",
    "            # Development (growth rate converted to 0-100 scale)\n",
    "            if 'annual_growth_rate_pct' in development and development['annual_growth_rate_pct'] is not None:\n",
    "                # Convert growth rate (-5% to +5%) to 0-100 scale\n",
    "                growth_score = min(100, max(0, (development['annual_growth_rate_pct'] + 5) * 10))\n",
    "                scores.append(('Development Potential', growth_score))\n",
    "            \n",
    "            # Noise (lower is better)\n",
    "            if 'estimated_noise_score' in traffic and traffic['estimated_noise_score'] is not None:\n",
    "                quiet_score = 100 - traffic['estimated_noise_score']\n",
    "                scores.append(('Quietness', quiet_score))\n",
    "            \n",
    "            # Calculate overall score\n",
    "            if scores:\n",
    "                overall_score = int(sum(score for _, score in scores) / len(scores))\n",
    "            else:\n",
    "                overall_score = None\n",
    "            \n",
    "            # Determine overall rating\n",
    "            if overall_score is not None:\n",
    "                if overall_score >= 80:\n",
    "                    overall_rating = \"Excellent\"\n",
    "                elif overall_score >= 70:\n",
    "                    overall_rating = \"Very Good\"\n",
    "                elif overall_score >= 60:\n",
    "                    overall_rating = \"Good\"\n",
    "                elif overall_score >= 50:\n",
    "                    overall_rating = \"Average\"\n",
    "                elif overall_score >= 40:\n",
    "                    overall_rating = \"Below Average\"\n",
    "                else:\n",
    "                    overall_rating = \"Poor\"\n",
    "            else:\n",
    "                overall_rating = \"Unknown\"\n",
    "            \n",
    "            # Compile report\n",
    "            report = {\n",
    "                \"property_location\": location_data,\n",
    "                \"overall_score\": overall_score,\n",
    "                \"overall_rating\": overall_rating,\n",
    "                \"category_scores\": {name: score for name, score in scores},\n",
    "                \"flood_risk_analysis\": flood_risk,\n",
    "                \"sun_exposure_analysis\": sun_exposure,\n",
    "                \"neighborhood_development\": development,\n",
    "                \"traffic_noise_analysis\": traffic\n",
    "            }\n",
    "            \n",
    "            if value_prediction:\n",
    "                report[\"property_value_prediction\"] = value_prediction\n",
    "            \n",
    "            return report\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Report generation error: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "        \n",
    "        \n",
    "#########################################################################\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "    def enhanced_geocode_address(self, address):\n",
    "        \"\"\"Enhanced geocoding with multiple providers and retry logic.\"\"\"\n",
    "        geocoders = [\n",
    "            (Nominatim(user_agent=\"property_analyzer\"), \"Nominatim\"),\n",
    "            (ArcGIS(), \"ArcGIS\"),\n",
    "        ]\n",
    "\n",
    "        # Try each geocoder in order\n",
    "        for geocoder, name in geocoders:\n",
    "            try:\n",
    "                print(f\"Trying geocoder: {name}\")\n",
    "                location = geocoder.geocode(address, timeout=10)\n",
    "                if location:\n",
    "                    print(f\"Successfully geocoded with {name}\")\n",
    "                    return {\n",
    "                        'lat': location.latitude,\n",
    "                        'lon': location.longitude,\n",
    "                        'address': location.address,\n",
    "                        'provider': name\n",
    "                    }\n",
    "            except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
    "                print(f\"Error with {name} geocoder: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error with {name} geocoder: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Fall back to the original simulation approach if all geocoders fail\n",
    "        print(f\"All geocoders failed for address: {address}, using simulated location data\")\n",
    "        return {\n",
    "            'lat': random.uniform(30, 45),\n",
    "            'lon': random.uniform(-120, -70),\n",
    "            'address': address,\n",
    "            'provider': 'simulation'\n",
    "        }\n",
    "\n",
    "    def get_property_details(self, address, api_key=None):\n",
    "        \"\"\"\n",
    "        Retrieve property details from a real estate API.\n",
    "        \"\"\"\n",
    "        if api_key is None:\n",
    "            api_key = os.getenv(\"REAL_ESTATE_API_KEY\")\n",
    "\n",
    "        if not api_key:\n",
    "            print(\"No API key available for real estate data\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Sample API call to a real estate data provider\n",
    "            base_url = \"https://api.realestatedata.example/v1/property\"\n",
    "            params = {\n",
    "                \"address\": address,\n",
    "                \"api_key\": api_key\n",
    "            }\n",
    "\n",
    "            response = requests.get(base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                return {\n",
    "                    \"property_size\": data.get(\"size_sqft\"),\n",
    "                    \"bedrooms\": data.get(\"bedrooms\"),\n",
    "                    \"bathrooms\": data.get(\"bathrooms\"),\n",
    "                    \"year_built\": data.get(\"year_built\"),\n",
    "                    \"lot_size\": data.get(\"lot_size_sqft\"),\n",
    "                    \"last_sale_price\": data.get(\"last_sale_price\"),\n",
    "                    \"last_sale_date\": data.get(\"last_sale_date\"),\n",
    "                    \"zoning\": data.get(\"zoning_code\"),\n",
    "                    \"property_type\": data.get(\"property_type\")\n",
    "                }\n",
    "            else:\n",
    "                print(f\"API error: Status code {response.status_code}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching property details: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_historical_sales(self, address=None, lat=None, lon=None):\n",
    "        \"\"\"\n",
    "        Retrieve historical sales data for a property.\n",
    "        \"\"\"\n",
    "        api_key = os.getenv(\"REAL_ESTATE_API_KEY\")\n",
    "\n",
    "        if not api_key:\n",
    "            print(\"No API key available for sales history data\")\n",
    "            return self._simulate_sales_history()\n",
    "\n",
    "        try:\n",
    "            # Determine query parameter - address or coordinates\n",
    "            params = {\"api_key\": api_key}\n",
    "\n",
    "            if address:\n",
    "                params[\"address\"] = address\n",
    "            elif lat is not None and lon is not None:\n",
    "                params[\"lat\"] = lat\n",
    "                params[\"lon\"] = lon\n",
    "            else:\n",
    "                return self._simulate_sales_history()\n",
    "\n",
    "            # Make API request\n",
    "            base_url = \"https://api.realestatedata.example/v1/sales_history\"\n",
    "            response = requests.get(base_url, params=params)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"API error: Status code {response.status_code}\")\n",
    "                return self._simulate_sales_history()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching sales history: {e}\")\n",
    "            return self._simulate_sales_history()\n",
    "\n",
    "    def _simulate_sales_history(self):\n",
    "        \"\"\"\n",
    "        Generate simulated sales history when API data isn't available.\n",
    "        \"\"\"\n",
    "        current_year = datetime.now().year\n",
    "        current_price = random.uniform(200000, 800000)\n",
    "\n",
    "        history = []\n",
    "\n",
    "        # Generate 3-5 past sales\n",
    "        num_sales = random.randint(3, 5)\n",
    "\n",
    "        for i in range(num_sales):\n",
    "            years_back = random.randint(2, 8) * (i + 1)\n",
    "            sale_year = current_year - years_back\n",
    "\n",
    "            # Each previous sale is some percentage lower\n",
    "            discount_factor = random.uniform(0.70, 0.90)\n",
    "            previous_price = current_price * discount_factor\n",
    "\n",
    "            history.append({\n",
    "                \"sale_date\": f\"{sale_year}-{random.randint(1, 12):02d}-{random.randint(1, 28):02d}\",\n",
    "                \"sale_price\": int(previous_price),\n",
    "                \"source\": \"simulation\"\n",
    "            })\n",
    "\n",
    "            current_price = previous_price\n",
    "\n",
    "        # Sort by date, most recent first\n",
    "        history.sort(key=lambda x: x[\"sale_date\"], reverse=True)\n",
    "\n",
    "        return {\n",
    "            \"sales_history\": history,\n",
    "            \"average_annual_appreciation\": round(random.uniform(2.0, 8.0), 2),\n",
    "            \"data_source\": \"simulation\"\n",
    "        }\n",
    "\n",
    "    def analyze_school_district(self, location_data):\n",
    "        \"\"\"\n",
    "        Analyze school district quality and nearby schools.\n",
    "        \"\"\"\n",
    "        api_key = os.getenv(\"EDUCATION_API_KEY\")\n",
    "\n",
    "        if not api_key:\n",
    "            return self._simulate_school_data(location_data)\n",
    "\n",
    "        try:\n",
    "            lat = location_data['lat']\n",
    "            lon = location_data['lon']\n",
    "\n",
    "            base_url = \"https://api.education.example/v1/schools/nearby\"\n",
    "            params = {\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "                \"radius\": 5,  # 5 miles\n",
    "                \"api_key\": api_key\n",
    "            }\n",
    "\n",
    "            response = requests.get(base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return self._simulate_school_data(location_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching school data: {e}\")\n",
    "            return self._simulate_school_data(location_data)\n",
    "\n",
    "    def _simulate_school_data(self, location_data):\n",
    "        \"\"\"\n",
    "        Generate simulated school district data.\n",
    "        \"\"\"\n",
    "        # Use location to influence school quality\n",
    "        lat = location_data['lat']\n",
    "        lon = location_data['lon']\n",
    "\n",
    "        # Use latitude as a factor in determining school quality\n",
    "        lat_factor = (lat - 30) / 15  # Normalize between 0-1 for latitudes 30-45\n",
    "        lat_factor = max(0, min(1, lat_factor))\n",
    "\n",
    "        # Use longitude as a random seed\n",
    "        random.seed(int((lon + 180) * 100) + 5)\n",
    "\n",
    "        # Create simulated elementary schools\n",
    "        elementary_schools = []\n",
    "        for i in range(random.randint(2, 4)):\n",
    "            quality_base = random.uniform(0.3, 0.9) + lat_factor * 0.3\n",
    "            quality_score = min(10, max(1, quality_score_to_rating(quality_base * 10)))\n",
    "\n",
    "            elementary_schools.append({\n",
    "                \"name\": f\"Elementary School #{i+1}\",\n",
    "                \"distance_miles\": round(random.uniform(0.2, 3.0), 1),\n",
    "                \"rating\": quality_score,\n",
    "                \"grades\": \"K-5\"\n",
    "            })\n",
    "\n",
    "        # Create simulated middle schools\n",
    "        middle_schools = []\n",
    "        for i in range(random.randint(1, 3)):\n",
    "            quality_base = random.uniform(0.3, 0.9) + lat_factor * 0.3\n",
    "            quality_score = min(10, max(1, quality_score_to_rating(quality_base * 10)))\n",
    "\n",
    "            middle_schools.append({\n",
    "                \"name\": f\"Middle School #{i+1}\",\n",
    "                \"distance_miles\": round(random.uniform(0.5, 4.0), 1),\n",
    "                \"rating\": quality_score,\n",
    "                \"grades\": \"6-8\"\n",
    "            })\n",
    "\n",
    "        # Create simulated high schools\n",
    "        high_schools = []\n",
    "        for i in range(random.randint(1, 2)):\n",
    "            quality_base = random.uniform(0.3, 0.9) + lat_factor * 0.3\n",
    "            quality_score = min(10, max(1, quality_score_to_rating(quality_base * 10)))\n",
    "\n",
    "            high_schools.append({\n",
    "                \"name\": f\"High School #{i+1}\",\n",
    "                \"distance_miles\": round(random.uniform(0.8, 5.0), 1),\n",
    "                \"rating\": quality_score,\n",
    "                \"grades\": \"9-12\"\n",
    "            })\n",
    "\n",
    "        # Calculate district average rating\n",
    "        all_schools = elementary_schools + middle_schools + high_schools\n",
    "        avg_rating = sum(school[\"rating\"] for school in all_schools) / len(all_schools)\n",
    "\n",
    "        # Determine overall quality category\n",
    "        if avg_rating >= 8.5:\n",
    "            quality_category = \"Excellent\"\n",
    "        elif avg_rating >= 7.0:\n",
    "            quality_category = \"Very Good\"\n",
    "        elif avg_rating >= 5.5:\n",
    "            quality_category = \"Good\"\n",
    "        elif avg_rating >= 4.0:\n",
    "            quality_category = \"Average\"\n",
    "        else:\n",
    "            quality_category = \"Below Average\"\n",
    "\n",
    "        return {\n",
    "            \"district_name\": \"Simulated School District\",\n",
    "            \"district_rating\": round(avg_rating, 1),\n",
    "            \"district_quality\": quality_category,\n",
    "            \"elementary_schools\": elementary_schools,\n",
    "            \"middle_schools\": middle_schools,\n",
    "            \"high_schools\": high_schools,\n",
    "            \"data_source\": \"simulation\"\n",
    "        }\n",
    "\n",
    "    def quality_score_to_rating(score):\n",
    "        \"\"\"Convert a 0-10 quality score to a 1-10 rating.\"\"\"\n",
    "        return round(score)\n",
    "\n",
    "    def analyze_crime_rates(self, location_data):\n",
    "        \"\"\"\n",
    "        Analyze crime rates in the area.\n",
    "        \"\"\"\n",
    "        api_key = os.getenv(\"CRIME_API_KEY\")\n",
    "\n",
    "        if not api_key:\n",
    "            return self._simulate_crime_data(location_data)\n",
    "\n",
    "        try:\n",
    "            lat = location_data['lat']\n",
    "            lon = location_data['lon']\n",
    "\n",
    "            base_url = \"https://api.crimedata.example/v1/stats\"\n",
    "            params = {\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "                \"radius\": 2,  # 2 miles\n",
    "                \"api_key\": api_key\n",
    "            }\n",
    "\n",
    "            response = requests.get(base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return self._simulate_crime_data(location_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching crime data: {e}\")\n",
    "            return self._simulate_crime_data(location_data)\n",
    "\n",
    "    def _simulate_crime_data(self, location_data):\n",
    "        \"\"\"\n",
    "        Generate simulated crime data.\n",
    "        \"\"\"\n",
    "        # Use location to influence crime rates\n",
    "        lat = location_data['lat']\n",
    "        lon = location_data['lon']\n",
    "\n",
    "        # Use latitude as a factor (lower latitude = higher crime in this simulation)\n",
    "        lat_factor = 1 - (lat - 30) / 15  # Normalize between 0-1 for latitudes 30-45\n",
    "        lat_factor = max(0, min(1, lat_factor))\n",
    "\n",
    "        # Use longitude as a random seed\n",
    "        random.seed(int((lon + 180) * 100) + 6)\n",
    "\n",
    "        # Base crime rate influenced by latitude\n",
    "        base_crime_rate = lat_factor * 60 + random.uniform(-20, 20)\n",
    "        base_crime_rate = max(0, min(100, base_crime_rate))\n",
    "\n",
    "        # Crime categories and their rates\n",
    "        crime_categories = {\n",
    "            \"violent\": base_crime_rate * random.uniform(0.1, 0.3),\n",
    "            \"property\": base_crime_rate * random.uniform(0.4, 0.7),\n",
    "            \"other\": base_crime_rate * random.uniform(0.2, 0.4)\n",
    "        }\n",
    "\n",
    "        # National averages (simulated)\n",
    "        national_avg = {\n",
    "            \"violent\": 30.0,\n",
    "            \"property\": 45.0,\n",
    "            \"other\": 25.0\n",
    "        }\n",
    "\n",
    "        # Calculate percentages compared to national average\n",
    "        comparison = {}\n",
    "        for category, rate in crime_categories.items():\n",
    "            if national_avg[category] > 0:\n",
    "                comparison[category] = (rate / national_avg[category]) * 100\n",
    "            else:\n",
    "                comparison[category] = 100\n",
    "\n",
    "        # Overall safety score (100 = safest)\n",
    "        safety_score = 100 - base_crime_rate\n",
    "\n",
    "        # Safety level\n",
    "        if safety_score >= 80:\n",
    "            safety_level = \"Very Safe\"\n",
    "        elif safety_score >= 60:\n",
    "            safety_level = \"Safe\"\n",
    "        elif safety_score >= 40:\n",
    "            safety_level = \"Moderate\"\n",
    "        elif safety_score >= 20:\n",
    "            safety_level = \"Concerning\"\n",
    "        else:\n",
    "            safety_level = \"High Crime Area\"\n",
    "\n",
    "        return {\n",
    "            \"safety_score\": int(safety_score),\n",
    "            \"safety_level\": safety_level,\n",
    "            \"crime_rates\": {\n",
    "                \"violent\": round(crime_categories[\"violent\"], 1),\n",
    "                \"property\": round(crime_categories[\"property\"], 1),\n",
    "                \"other\": round(crime_categories[\"other\"], 1)\n",
    "            },\n",
    "            \"comparison_to_national_avg\": {\n",
    "                \"violent\": round(comparison[\"violent\"], 1),\n",
    "                \"property\": round(comparison[\"property\"], 1),\n",
    "                \"other\": round(comparison[\"other\"], 1)\n",
    "            },\n",
    "            \"data_source\": \"simulation\"\n",
    "        }\n",
    "\n",
    "    def analyze_amenities_proximity(self, location_data, radius_km=2):\n",
    "        \"\"\"\n",
    "        Analyze proximity to amenities like shopping, parks, etc.\n",
    "        \"\"\"\n",
    "        api_key = os.getenv(\"AMENITIES_API_KEY\")\n",
    "\n",
    "        if not api_key:\n",
    "            return self._simulate_amenities_data(location_data, radius_km)\n",
    "\n",
    "        try:\n",
    "            lat = location_data['lat']\n",
    "            lon = location_data['lon']\n",
    "\n",
    "            base_url = \"https://api.amenities.example/v1/nearby\"\n",
    "            params = {\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "                \"radius\": radius_km,\n",
    "                \"api_key\": api_key\n",
    "            }\n",
    "\n",
    "            response = requests.get(base_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return self._simulate_amenities_data(location_data, radius_km)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching amenities data: {e}\")\n",
    "            return self._simulate_amenities_data(location_data, radius_km)\n",
    "\n",
    "    def _simulate_amenities_data(self, location_data, radius_km=2):\n",
    "        \"\"\"\n",
    "        Generate simulated amenities data.\n",
    "        \"\"\"\n",
    "        # Use location to influence amenity density\n",
    "        lat = location_data['lat']\n",
    "        lon = location_data['lon']\n",
    "\n",
    "        # Use latitude as a factor (lower latitude = more urban/more amenities)\n",
    "        lat_factor = 1 - (lat - 30) / 15  # Normalize between 0-1 for latitudes 30-45\n",
    "        lat_factor = max(0, min(1, lat_factor))\n",
    "\n",
    "        # Use longitude as a random seed\n",
    "        random.seed(int((lon + 180) * 100) + 7)\n",
    "\n",
    "        # Define amenity categories and counts\n",
    "        amenity_categories = {\n",
    "            \"restaurants\": int(lat_factor * 20 + random.uniform(1, 10)),\n",
    "            \"grocery_stores\": int(lat_factor * 5 + random.uniform(0, 3)),\n",
    "            \"shopping\": int(lat_factor * 8 + random.uniform(0, 5)),\n",
    "            \"parks\": int((1 - lat_factor) * 6 + lat_factor * 3 + random.uniform(0, 3)),\n",
    "            \"gyms\": int(lat_factor * 4 + random.uniform(0, 2)),\n",
    "            \"schools\": int(3 + random.uniform(0, 3)),\n",
    "            \"medical\": int(lat_factor * 6 + random.uniform(0, 3))\n",
    "        }\n",
    "\n",
    "        # Calculate closest amenities\n",
    "        closest_amenities = {}\n",
    "        for category in amenity_categories:\n",
    "            if amenity_categories[category] > 0:\n",
    "                closest_amenities[category] = round(random.uniform(0.1, radius_km), 1)\n",
    "            else:\n",
    "                closest_amenities[category] = None\n",
    "\n",
    "        # Calculate convenience score (0-100)\n",
    "        if sum(amenity_categories.values()) > 0:\n",
    "            convenience_base = min(100, lat_factor * 70 + sum(amenity_categories.values()) * 2)\n",
    "            convenience_score = int(convenience_base + random.uniform(-10, 10))\n",
    "            convenience_score = max(0, min(100, convenience_score))\n",
    "        else:\n",
    "            convenience_score = int(lat_factor * 30 + random.uniform(0, 20))\n",
    "\n",
    "        # Determine walkability rating\n",
    "        if convenience_score >= 80:\n",
    "            walkability = \"Excellent\"\n",
    "        elif convenience_score >= 60:\n",
    "            walkability = \"Very Good\"\n",
    "        elif convenience_score >= 40:\n",
    "            walkability = \"Good\"\n",
    "        elif convenience_score >= 20:\n",
    "            walkability = \"Limited\"\n",
    "        else:\n",
    "            walkability = \"Poor\"\n",
    "\n",
    "        return {\n",
    "            \"total_amenities\": sum(amenity_categories.values()),\n",
    "            \"amenity_counts\": amenity_categories,\n",
    "            \"closest_amenities_km\": closest_amenities,\n",
    "            \"convenience_score\": convenience_score,\n",
    "            \"walkability_rating\": walkability,\n",
    "            \"data_source\": \"simulation\"\n",
    "        }\n",
    "\n",
    "    def generate_enhanced_comprehensive_report(self, address=None, lat=None, lon=None,\n",
    "                                           current_value=None, property_size=None, bedrooms=None):\n",
    "        \"\"\"Generate an enhanced comprehensive property analysis report with additional data sources.\"\"\"\n",
    "        try:\n",
    "            # Get location data using the enhanced geocoder\n",
    "            location_data = self.get_property_coordinates(address, lat, lon)\n",
    "            if not location_data:\n",
    "                return {\"error\": \"Could not geocode the provided address or coordinates\"}\n",
    "\n",
    "            print(f\"Analyzing property at: {location_data['address']}\")\n",
    "\n",
    "            # Try to get real property details if available\n",
    "            property_details = None\n",
    "            if address:\n",
    "                property_details = self.get_property_details(address)\n",
    "\n",
    "            # If we got property details, use those values instead of passed parameters\n",
    "            if property_details:\n",
    "                if not property_size and 'property_size' in property_details:\n",
    "                    property_size = property_details['property_size']\n",
    "                if not bedrooms and 'bedrooms' in property_details:\n",
    "                    bedrooms = property_details['bedrooms']\n",
    "                if not current_value and 'last_sale_price' in property_details:\n",
    "                    current_value = property_details['last_sale_price']\n",
    "\n",
    "            # Run all original analyses\n",
    "            flood_risk = self.analyze_flood_risk(location_data)\n",
    "            sun_exposure = self.analyze_sun_exposure(location_data)\n",
    "            development = self.analyze_neighborhood_development(location_data)\n",
    "            traffic = self.analyze_traffic_noise(location_data)\n",
    "\n",
    "            # Run new enhanced analyses\n",
    "            sales_history = self.get_historical_sales(address, location_data['lat'], location_data['lon'])\n",
    "            school_data = self.analyze_school_district(location_data)\n",
    "            crime_data = self.analyze_crime_rates(location_data)\n",
    "            amenities_data = self.analyze_amenities_proximity(location_data)\n",
    "\n",
    "            value_prediction = None\n",
    "            if current_value is not None:\n",
    "                value_prediction = self.predict_property_value(\n",
    "                    location_data, current_value, property_size, bedrooms\n",
    "                )\n",
    "\n",
    "            # Generate overall property score (0-100) including new factors\n",
    "            scores = []\n",
    "\n",
    "            # Original scores\n",
    "            if 'flood_risk_score' in flood_risk and flood_risk['flood_risk_score'] is not None:\n",
    "                flood_score = 100 - flood_risk['flood_risk_score']\n",
    "                scores.append(('Flood Safety', flood_score))\n",
    "\n",
    "            if 'average_sun_score' in sun_exposure and sun_exposure['average_sun_score'] is not None:\n",
    "                scores.append(('Sun Exposure', sun_exposure['average_sun_score']))\n",
    "\n",
    "            if 'annual_growth_rate_pct' in development and development['annual_growth_rate_pct'] is not None:\n",
    "                growth_score = min(100, max(0, (development['annual_growth_rate_pct'] + 5) * 10))\n",
    "                scores.append(('Development Potential', growth_score))\n",
    "\n",
    "            if 'estimated_noise_score' in traffic and traffic['estimated_noise_score'] is not None:\n",
    "                quiet_score = 100 - traffic['estimated_noise_score']\n",
    "                scores.append(('Quietness', quiet_score))\n",
    "\n",
    "            # Add new factors to scores\n",
    "            if school_data and 'district_rating' in school_data:\n",
    "                school_score = school_data['district_rating'] * 10  # Convert 0-10 to 0-100\n",
    "                scores.append(('School Quality', school_score))\n",
    "\n",
    "            if crime_data and 'safety_score' in crime_data:\n",
    "                scores.append(('Safety', crime_data['safety_score']))\n",
    "\n",
    "            if amenities_data and 'convenience_score' in amenities_data:\n",
    "                scores.append(('Convenience', amenities_data['convenience_score']))\n",
    "\n",
    "            # Calculate overall score\n",
    "            if scores:\n",
    "                overall_score = int(sum(score for _, score in scores) / len(scores))\n",
    "            else:\n",
    "                overall_score = None\n",
    "\n",
    "            # Determine overall rating\n",
    "            if overall_score is not None:\n",
    "                if overall_score >= 80:\n",
    "                    overall_rating = \"Excellent\"\n",
    "                elif overall_score >= 70:\n",
    "                    overall_rating = \"Very Good\"\n",
    "                elif overall_score >= 60:\n",
    "                    overall_rating = \"Good\"\n",
    "                elif overall_score >= 50:\n",
    "                    overall_rating = \"Average\"\n",
    "                elif overall_score >= 40:\n",
    "                    overall_rating = \"Below Average\"\n",
    "                else:\n",
    "                    overall_rating = \"Poor\"\n",
    "            else:\n",
    "                overall_rating = \"Unknown\"\n",
    "\n",
    "            # Compile enhanced report\n",
    "            report = {\n",
    "                \"property_location\": location_data,\n",
    "                \"property_details\": property_details,\n",
    "                \"overall_score\": overall_score,\n",
    "                \"overall_rating\": overall_rating,\n",
    "                \"category_scores\": {name: score for name, score in scores},\n",
    "                \"flood_risk_analysis\": flood_risk,\n",
    "                \"sun_exposure_analysis\": sun_exposure,\n",
    "                \"neighborhood_development\": development,\n",
    "                \"traffic_noise_analysis\": traffic,\n",
    "                \"sales_history\": sales_history,\n",
    "                \"school_district_analysis\": school_data,\n",
    "                \"crime_analysis\": crime_data,\n",
    "                \"amenities_analysis\": amenities_data\n",
    "            }\n",
    "\n",
    "            if value_prediction:\n",
    "                report[\"property_value_prediction\"] = value_prediction\n",
    "\n",
    "            return report\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Enhanced report generation error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "############################################################################\n",
    "############################################################################\n",
    "    \n",
    "    \n",
    "    def visualize_report(self, report, output_file=None):\n",
    "        \"\"\"Generate enhanced visualizations for the property analysis report with new data sources.\"\"\"\n",
    "        if \"error\" in report:\n",
    "            print(f\"Cannot visualize report with error: {report['error']}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Create figure with more subplots for the new data\n",
    "            fig = plt.figure(figsize=(20, 16))\n",
    "            fig.suptitle(f\"Enhanced Property Analysis: {report['property_location']['address']}\", fontsize=16)\n",
    "\n",
    "            # Original plots (modified to fit new layout)\n",
    "            # Plot 1: Category Scores Spider Chart (Polar)\n",
    "            if \"category_scores\" in report and report[\"category_scores\"]:\n",
    "                categories = list(report[\"category_scores\"].keys())\n",
    "                values = list(report[\"category_scores\"].values())\n",
    "\n",
    "                # Complete the loop for the spider chart\n",
    "                categories.append(categories[0])\n",
    "                values.append(values[0])\n",
    "\n",
    "                # Convert to radians for plotting\n",
    "                angles = np.linspace(0, 2*np.pi, len(categories), endpoint=True)\n",
    "\n",
    "                # Create a polar subplot\n",
    "                ax1 = fig.add_subplot(3, 3, 1, polar=True)\n",
    "                ax1.plot(angles, values, 'o-', linewidth=2)\n",
    "                ax1.fill(angles, values, alpha=0.25)\n",
    "                ax1.set_xticks(angles[:-1])\n",
    "                ax1.set_xticklabels(categories[:-1], fontsize=8)\n",
    "                ax1.set_ylim(0, 100)\n",
    "                ax1.set_title(\"Property Quality Factors\")\n",
    "                ax1.grid(True)\n",
    "\n",
    "            # Plot 2: Neighborhood Development Trend\n",
    "            ax2 = fig.add_subplot(3, 3, 2)\n",
    "            if (\"neighborhood_development\" in report and\n",
    "                \"development_trend\" in report[\"neighborhood_development\"] and\n",
    "                report[\"neighborhood_development\"][\"development_trend\"]):\n",
    "\n",
    "                trend = report[\"neighborhood_development\"][\"development_trend\"]\n",
    "                years = [item[\"year\"] for item in trend]\n",
    "                values = [item[\"built_up_percentage\"] for item in trend]\n",
    "\n",
    "                ax2.plot(years, values, 'o-', color='green')\n",
    "                ax2.set_title(\"Neighborhood Development Trend\")\n",
    "                ax2.set_xlabel(\"Year\")\n",
    "                ax2.set_ylabel(\"Built-up Area (%)\")\n",
    "                ax2.grid(True)\n",
    "\n",
    "            # Plot 3: Sun Exposure by Season and Time\n",
    "            ax3 = fig.add_subplot(3, 3, 3)\n",
    "            if (\"sun_exposure_analysis\" in report and\n",
    "                \"detailed_sun_exposure\" in report[\"sun_exposure_analysis\"]):\n",
    "\n",
    "                sun_data = report[\"sun_exposure_analysis\"][\"detailed_sun_exposure\"]\n",
    "                seasons = sorted(set(item[\"season\"] for item in sun_data))\n",
    "                times = sorted(set(item[\"time_of_day\"] for item in sun_data))\n",
    "\n",
    "                data = np.zeros((len(seasons), len(times)))\n",
    "                season_idx = {season: i for i, season in enumerate(seasons)}\n",
    "                time_idx = {time: j for j, time in enumerate(times)}\n",
    "\n",
    "                for item in sun_data:\n",
    "                    i = season_idx[item[\"season\"]]\n",
    "                    j = time_idx[item[\"time_of_day\"]]\n",
    "                    data[i, j] = item[\"sun_exposure_score\"]\n",
    "\n",
    "                im = ax3.imshow(data, cmap='YlOrRd')\n",
    "\n",
    "                # Set ticks and labels\n",
    "                ax3.set_xticks(np.arange(len(times)))\n",
    "                ax3.set_yticks(np.arange(len(seasons)))\n",
    "                ax3.set_xticklabels(times)\n",
    "                ax3.set_yticklabels(seasons)\n",
    "\n",
    "                # Rotate the tick labels\n",
    "                plt.setp(ax3.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "                # Add colorbar\n",
    "                cbar = plt.colorbar(im, ax=ax3)\n",
    "                cbar.set_label('Sun Exposure Score')\n",
    "\n",
    "                ax3.set_title(\"Sun Exposure by Season and Time\")\n",
    "\n",
    "                # Add text annotations in the cells\n",
    "                for i in range(len(seasons)):\n",
    "                    for j in range(len(times)):\n",
    "                        text = ax3.text(j, i, int(data[i, j]),\n",
    "                                    ha=\"center\", va=\"center\", color=\"black\")\n",
    "                        \n",
    "            \n",
    "                   # NEW PLOT 4: Historical Sales Trend\n",
    "            ax4 = fig.add_subplot(3, 3, 4)\n",
    "            if \"sales_history\" in report and \"sales_history\" in report[\"sales_history\"]:\n",
    "                sales = report[\"sales_history\"][\"sales_history\"]\n",
    "                if sales:\n",
    "                    # Extract dates and prices\n",
    "                    dates = [sale[\"sale_date\"] for sale in sales]\n",
    "                    prices = [sale[\"sale_price\"] for sale in sales]\n",
    "\n",
    "                    # Sort by date\n",
    "                    date_price = sorted(zip(dates, prices), key=lambda x: x[0])\n",
    "                    dates = [dp[0] for dp in date_price]\n",
    "                    prices = [dp[1] for dp in date_price]\n",
    "\n",
    "                    # Format dates for better display\n",
    "                    dates = [d.split(\"-\")[0] for d in dates]  # Just show the year\n",
    "\n",
    "                    ax4.plot(dates, prices, 'o-', color='blue')\n",
    "                    ax4.set_title(\"Historical Sales Prices\")\n",
    "                    ax4.set_xlabel(\"Year\")\n",
    "                    ax4.set_ylabel(\"Sale Price ($)\")\n",
    "\n",
    "                    # Format y-axis to show thousands/millions\n",
    "                    ax4.get_yaxis().set_major_formatter(\n",
    "                        plt.FuncFormatter(lambda x, loc: \"${:,}\".format(int(x)))\n",
    "                    )\n",
    "\n",
    "                    # Rotate x-axis labels for better readability\n",
    "                    plt.setp(ax4.get_xticklabels(), rotation=45)\n",
    "                    ax4.grid(True)\n",
    "\n",
    "            \n",
    "            # Plot 4: Overall Score Gauge\n",
    "            ax4 = fig.add_subplot(2, 2, 4)\n",
    "            if \"overall_score\" in report and report[\"overall_score\"] is not None:\n",
    "                # Create a simple gauge\n",
    "                score = report[\"overall_score\"]\n",
    "                \n",
    "                # Create gauge\n",
    "                gauge_colors = ['#FF4136', '#FF851B', '#FFDC00', '#2ECC40', '#0074D9']\n",
    "                bounds = [0, 20, 40, 60, 80, 100]\n",
    "                norm = plt.Normalize(0, 100)\n",
    "                \n",
    "                # Draw gauge background\n",
    "                for i in range(len(bounds)-1):\n",
    "                    ax4.barh(0, bounds[i+1]-bounds[i], left=bounds[i], height=0.5,\n",
    "                        color=gauge_colors[i], alpha=0.7)\n",
    "                \n",
    "                # Draw score indicator\n",
    "                ax4.barh(0, 2, left=score-1, height=0.7, color='black')\n",
    "                \n",
    "                # Add score text\n",
    "                ax4.text(50, -0.5, f\"Overall Score: {score}/100\",\n",
    "                    ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "                ax4.text(50, 0.7, f\"Rating: {report['overall_rating']}\",\n",
    "                    ha='center', va='center', fontsize=12)\n",
    "                \n",
    "                # Clean up plot\n",
    "                ax4.set_xlim(0, 100)\n",
    "                ax4.set_ylim(-1, 1)\n",
    "                ax4.set_title(\"Property Score\")\n",
    "                ax4.axis('off')\n",
    "            \n",
    "            # Add overall recommendations and key insights\n",
    "            recommendations = []\n",
    "            \n",
    "            # Flood risk recommendation\n",
    "            if \"flood_risk_analysis\" in report and \"flood_risk_level\" in report[\"flood_risk_analysis\"]:\n",
    "                risk_level = report[\"flood_risk_analysis\"][\"flood_risk_level\"]\n",
    "                if risk_level in [\"High\", \"Very High\"]:\n",
    "                    recommendations.append(\"⚠️ High flood risk detected. Consider flood insurance and mitigation measures.\")\n",
    "                elif risk_level == \"Moderate\":\n",
    "                    recommendations.append(\"⚠️ Moderate flood risk. Verify if flood insurance is recommended.\")\n",
    "            \n",
    "            # Sun exposure recommendation\n",
    "            if \"sun_exposure_analysis\" in report and \"sun_exposure_rating\" in report[\"sun_exposure_analysis\"]:\n",
    "                sun_rating = report[\"sun_exposure_analysis\"][\"sun_exposure_rating\"]\n",
    "                if sun_rating in [\"Poor\", \"Moderate\"]:\n",
    "                    recommendations.append(\"☀️ Limited sun exposure may increase heating/lighting costs and affect garden potential.\")\n",
    "                elif sun_rating == \"Excellent\":\n",
    "                    recommendations.append(\"☀️ Excellent sun exposure - good potential for solar panels and gardening.\")\n",
    "            \n",
    "            # Development recommendation\n",
    "            if \"neighborhood_development\" in report and \"development_category\" in report[\"neighborhood_development\"]:\n",
    "                dev_category = report[\"neighborhood_development\"][\"development_category\"]\n",
    "                if dev_category in [\"Rapid Growth\", \"Moderate Growth\"]:\n",
    "                    recommendations.append(\"📈 Area shows strong development - potential for value appreciation but watch for increasing density.\")\n",
    "                elif dev_category == \"Declining\":\n",
    "                    recommendations.append(\"📉 Area shows declining development - may affect long-term property values.\")\n",
    "            \n",
    "            # Noise recommendation\n",
    "            if \"traffic_noise_analysis\" in report and \"estimated_noise_level\" in report[\"traffic_noise_analysis\"]:\n",
    "                noise_level = report[\"traffic_noise_analysis\"][\"estimated_noise_level\"]\n",
    "                if noise_level in [\"High\", \"Very High\"]:\n",
    "                    recommendations.append(\"🔊 High noise levels detected. Consider sound insulation if purchasing.\")\n",
    "            \n",
    "            # Value recommendation\n",
    "            if \"property_value_prediction\" in report and \"investment_potential\" in report[\"property_value_prediction\"]:\n",
    "                potential = report[\"property_value_prediction\"][\"investment_potential\"]\n",
    "                if potential in [\"Excellent\", \"Good\"]:\n",
    "                    recommendations.append(\"💰 Good investment potential with projected value appreciation.\")\n",
    "                elif potential == \"Below Average\":\n",
    "                    recommendations.append(\"💰 Below average investment potential - consider negotiating price or exploring other options.\")\n",
    "            \n",
    "            # Add recommendations to the plot\n",
    "            fig.text(0.5, 0.01, \"Key Insights & Recommendations:\", ha='center', fontsize=14, fontweight='bold')\n",
    "            for i, rec in enumerate(recommendations[:5]):  # Limit to top 5 recommendations\n",
    "                fig.text(0.5, -0.02 - i*0.02, f\"• {rec}\", ha='center', fontsize=10)\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "            \n",
    "            if output_file:\n",
    "                plt.savefig(output_file, bbox_inches='tight', dpi=300)\n",
    "                print(f\"Report visualization saved to {output_file}\")\n",
    "            \n",
    "            plt.show()\n",
    "            return fig\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Visualization error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main application function for Property Analyzer.\"\"\"\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Property Analyzer: AI-powered real estate assessment tool')\n",
    "    parser.add_argument('--address', type=str, help='Property address to analyze')\n",
    "    parser.add_argument('--lat', type=float, help='Property latitude (alternative to address)')\n",
    "    parser.add_argument('--lon', type=float, help='Property longitude (alternative to address)')\n",
    "    parser.add_argument('--value', type=float, help='Current property value for investment prediction')\n",
    "    parser.add_argument('--size', type=float, help='Property size in square feet/meters')\n",
    "    parser.add_argument('--bedrooms', type=int, help='Number of bedrooms')\n",
    "    parser.add_argument('--output', type=str, help='Output file for visualization (e.g., report.png)')\n",
    "    parser.add_argument('--interactive', action='store_true', help='Run in interactive mode')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = PropertyAnalyzer()\n",
    "    \n",
    "    if args.interactive:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Property Analyzer: AI-Powered Real Estate Assessment Tool\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Get property information\n",
    "        address = input(\"Enter property address (or press Enter to use coordinates): \")\n",
    "        \n",
    "        lat, lon = None, None\n",
    "        if not address:\n",
    "            try:\n",
    "                lat = float(input(\"Enter latitude: \"))\n",
    "                lon = float(input(\"Enter longitude: \"))\n",
    "            except ValueError:\n",
    "                print(\"Error: Invalid coordinates\")\n",
    "                return\n",
    "        \n",
    "        # Get optional property details\n",
    "        value = None\n",
    "        try:\n",
    "            value_input = input(\"Enter current property value (optional, press Enter to skip): \")\n",
    "            if value_input:\n",
    "                value = float(value_input)\n",
    "        except ValueError:\n",
    "            print(\"Warning: Invalid value, skipping investment prediction\")\n",
    "        \n",
    "        size = None\n",
    "        try:\n",
    "            size_input = input(\"Enter property size in sq ft/m (optional, press Enter to skip): \")\n",
    "            if size_input:\n",
    "                size = float(size_input)\n",
    "        except ValueError:\n",
    "            print(\"Warning: Invalid size\")\n",
    "        \n",
    "        bedrooms = None\n",
    "        try:\n",
    "            bedrooms_input = input(\"Enter number of bedrooms (optional, press Enter to skip): \")\n",
    "            if bedrooms_input:\n",
    "                bedrooms = int(bedrooms_input)\n",
    "        except ValueError:\n",
    "            print(\"Warning: Invalid number of bedrooms\")\n",
    "        \n",
    "        output_file = input(\"Enter output file name for visualization (optional, press Enter to skip): \")\n",
    "        if not output_file:\n",
    "            output_file = None\n",
    "            \n",
    "        print(\"\\nAnalyzing property... (this may take a minute)\")\n",
    "        \n",
    "    else:\n",
    "        # Use command line arguments\n",
    "        address = args.address\n",
    "        lat = args.lat\n",
    "        lon = args.lon\n",
    "        value = args.value\n",
    "        size = args.size\n",
    "        bedrooms = args.bedrooms\n",
    "        output_file = args.output\n",
    "        \n",
    "        if not address and (lat is None or lon is None):\n",
    "            print(\"Error: Either address or coordinates (lat/lon) must be provided\")\n",
    "            return\n",
    "    \n",
    "    # Generate report\n",
    "    report = analyzer.generate_comprehensive_report(\n",
    "        address=address, \n",
    "        lat=lat, \n",
    "        lon=lon,\n",
    "        current_value=value,\n",
    "        property_size=size,\n",
    "        bedrooms=bedrooms\n",
    "    )\n",
    "    \n",
    "    if \"error\" in report:\n",
    "        print(f\"Error generating report: {report['error']}\")\n",
    "        return\n",
    "    \n",
    "    # Display text report\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"PROPERTY ANALYSIS REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Location: {report['property_location']['address']}\")\n",
    "    print(f\"Coordinates: {report['property_location']['lat']}, {report['property_location']['lon']}\")\n",
    "    print(f\"Overall Score: {report['overall_score']}/100 ({report['overall_rating']})\")\n",
    "    print(\"\\nCATEGORY SCORES:\")\n",
    "    for category, score in report.get('category_scores', {}).items():\n",
    "        print(f\"- {category}: {score}/100\")\n",
    "    \n",
    "    print(\"\\nFLOOD RISK ASSESSMENT:\")\n",
    "    flood = report.get('flood_risk_analysis', {})\n",
    "    print(f\"- Risk Level: {flood.get('flood_risk_level', 'Unknown')}\")\n",
    "    print(f\"- Risk Score: {flood.get('flood_risk_score', 'Unknown')}/100\")\n",
    "    print(f\"- Elevation: {flood.get('elevation_m', 'Unknown')} meters\")\n",
    "    print(f\"- Distance to Water: {flood.get('distance_to_water_m', 'Unknown')} meters\")\n",
    "    \n",
    "    print(\"\\nSUN EXPOSURE ASSESSMENT:\")\n",
    "    sun = report.get('sun_exposure_analysis', {})\n",
    "    print(f\"- Rating: {sun.get('sun_exposure_rating', 'Unknown')}\")\n",
    "    print(f\"- Average Score: {sun.get('average_sun_score', 'Unknown')}/100\")\n",
    "    \n",
    "    print(\"\\nNEIGHBORHOOD DEVELOPMENT:\")\n",
    "    dev = report.get('neighborhood_development', {})\n",
    "    print(f\"- Category: {dev.get('development_category', 'Unknown')}\")\n",
    "    print(f\"- Annual Growth Rate: {dev.get('annual_growth_rate_pct', 'Unknown')}%\")\n",
    "    print(f\"- Analysis Period: {dev.get('analysis_period', 'Unknown')}\")\n",
    "    \n",
    "    print(\"\\nTRAFFIC & NOISE ASSESSMENT:\")\n",
    "    noise = report.get('traffic_noise_analysis', {})\n",
    "    print(f\"- Noise Level: {noise.get('estimated_noise_level', 'Unknown')}\")\n",
    "    print(f\"- Noise Score: {noise.get('estimated_noise_score', 'Unknown')}/100\")\n",
    "    print(f\"- Distance to Highway: {noise.get('distance_to_highway_m', 'Unknown')} meters\")\n",
    "    print(f\"- Distance to Major Road: {noise.get('distance_to_major_road_m', 'Unknown')} meters\")\n",
    "    \n",
    "    if 'property_value_prediction' in report:\n",
    "        print(\"\\nPROPERTY VALUE PREDICTION:\")\n",
    "        value_pred = report['property_value_prediction']\n",
    "        print(f\"- Current Value: ${value_pred.get('current_value', 'Unknown'):,.2f}\")\n",
    "        print(f\"- Estimated Annual Appreciation: {value_pred.get('estimated_annual_appreciation_pct', 'Unknown')}%\")\n",
    "        print(f\"- 5-Year Projected Value: ${value_pred.get('five_year_projected_value', 'Unknown'):,.2f}\")\n",
    "        print(f\"- Projected Gain: {value_pred.get('projected_gain_pct', 'Unknown')}%\")\n",
    "        print(f\"- Investment Potential: {value_pred.get('investment_potential', 'Unknown')}\")\n",
    "    \n",
    "    # Generate visualization\n",
    "    analyzer.visualize_report(report, output_file)\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc576c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
